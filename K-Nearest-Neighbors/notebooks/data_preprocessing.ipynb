{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_prepocessing import convert_images_to_grayscale, remove_corrupt_images, split_images_into_train_validation_test, calculate_train_val_test_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variables\n",
    "root_directory = '../datasets/mnist_all/'\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing for corrupt images\n",
    "# remeoved_list = remove_corrupt_images(root_directory, class_names)\n",
    "# remeoved_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/mnist_all/0/0_1.png\n",
      "../datasets/mnist_all/0/0_1000.png\n",
      "../datasets/mnist_all/0/0_10005.png\n",
      "../datasets/mnist_all/0/0_10010.png\n",
      "../datasets/mnist_all/0/0_10022.png\n",
      "../datasets/mnist_all/0/0_10025.png\n",
      "../datasets/mnist_all/0/0_10026.png\n",
      "../datasets/mnist_all/0/0_10045.png\n",
      "../datasets/mnist_all/0/0_10069.png\n",
      "../datasets/mnist_all/0/0_10071.png\n",
      "../datasets/mnist_all/0/0_10080.png\n",
      "../datasets/mnist_all/0/0_10083.png\n",
      "../datasets/mnist_all/0/0_10107.png\n",
      "../datasets/mnist_all/0/0_10119.png\n",
      "../datasets/mnist_all/0/0_10120.png\n",
      "../datasets/mnist_all/0/0_10121.png\n",
      "../datasets/mnist_all/0/0_10128.png\n",
      "../datasets/mnist_all/0/0_10140.png\n",
      "../datasets/mnist_all/0/0_1015.png\n",
      "../datasets/mnist_all/0/0_10167.png\n",
      "../datasets/mnist_all/0/0_10168.png\n",
      "../datasets/mnist_all/0/0_10176.png\n",
      "../datasets/mnist_all/0/0_1018.png\n",
      "../datasets/mnist_all/0/0_10188.png\n",
      "../datasets/mnist_all/0/0_10195.png\n",
      "../datasets/mnist_all/0/0_10203.png\n",
      "../datasets/mnist_all/0/0_10204.png\n",
      "../datasets/mnist_all/0/0_10221.png\n",
      "../datasets/mnist_all/0/0_10230.png\n",
      "../datasets/mnist_all/0/0_10237.png\n",
      "../datasets/mnist_all/0/0_10240.png\n",
      "../datasets/mnist_all/0/0_10242.png\n",
      "../datasets/mnist_all/0/0_10245.png\n",
      "../datasets/mnist_all/0/0_10254.png\n",
      "../datasets/mnist_all/0/0_10259.png\n",
      "../datasets/mnist_all/0/0_10261.png\n",
      "../datasets/mnist_all/0/0_10265.png\n",
      "../datasets/mnist_all/0/0_10272.png\n",
      "../datasets/mnist_all/0/0_10276.png\n",
      "../datasets/mnist_all/0/0_1028.png\n",
      "../datasets/mnist_all/0/0_10283.png\n",
      "../datasets/mnist_all/0/0_1029.png\n",
      "../datasets/mnist_all/0/0_10323.png\n",
      "../datasets/mnist_all/0/0_10326.png\n",
      "../datasets/mnist_all/0/0_10334.png\n",
      "../datasets/mnist_all/0/0_10340.png\n",
      "../datasets/mnist_all/0/0_10343.png\n",
      "../datasets/mnist_all/0/0_10348.png\n",
      "../datasets/mnist_all/0/0_10352.png\n",
      "../datasets/mnist_all/0/0_10363.png\n",
      "../datasets/mnist_all/0/0_10366.png\n",
      "../datasets/mnist_all/0/0_10372.png\n",
      "../datasets/mnist_all/0/0_10380.png\n",
      "../datasets/mnist_all/0/0_10384.png\n",
      "../datasets/mnist_all/0/0_1040.png\n",
      "../datasets/mnist_all/0/0_10407.png\n",
      "../datasets/mnist_all/0/0_10425.png\n",
      "../datasets/mnist_all/0/0_10439.png\n",
      "../datasets/mnist_all/0/0_10456.png\n",
      "../datasets/mnist_all/0/0_1046.png\n",
      "../datasets/mnist_all/0/0_10469.png\n",
      "../datasets/mnist_all/0/0_10471.png\n",
      "../datasets/mnist_all/0/0_10479.png\n",
      "../datasets/mnist_all/0/0_10488.png\n",
      "../datasets/mnist_all/0/0_1049.png\n",
      "../datasets/mnist_all/0/0_10505.png\n",
      "../datasets/mnist_all/0/0_10523.png\n",
      "../datasets/mnist_all/0/0_10530.png\n",
      "../datasets/mnist_all/0/0_10531.png\n",
      "../datasets/mnist_all/0/0_10542.png\n",
      "../datasets/mnist_all/0/0_10563.png\n",
      "../datasets/mnist_all/0/0_10564.png\n",
      "../datasets/mnist_all/0/0_10579.png\n",
      "../datasets/mnist_all/0/0_10599.png\n",
      "../datasets/mnist_all/0/0_10604.png\n",
      "../datasets/mnist_all/0/0_10625.png\n",
      "../datasets/mnist_all/0/0_10645.png\n",
      "../datasets/mnist_all/0/0_10664.png\n",
      "../datasets/mnist_all/0/0_10689.png\n",
      "../datasets/mnist_all/0/0_10691.png\n",
      "../datasets/mnist_all/0/0_10700.png\n",
      "../datasets/mnist_all/0/0_10705.png\n",
      "../datasets/mnist_all/0/0_10732.png\n",
      "../datasets/mnist_all/0/0_10747.png\n",
      "../datasets/mnist_all/0/0_10750.png\n",
      "../datasets/mnist_all/0/0_10755.png\n",
      "../datasets/mnist_all/0/0_1076.png\n",
      "../datasets/mnist_all/0/0_10773.png\n",
      "../datasets/mnist_all/0/0_1078.png\n",
      "../datasets/mnist_all/0/0_10781.png\n",
      "../datasets/mnist_all/0/0_108.png\n",
      "../datasets/mnist_all/0/0_10801.png\n",
      "../datasets/mnist_all/0/0_10806.png\n",
      "../datasets/mnist_all/0/0_10821.png\n",
      "../datasets/mnist_all/0/0_10840.png\n",
      "../datasets/mnist_all/0/0_10844.png\n",
      "../datasets/mnist_all/0/0_10849.png\n",
      "../datasets/mnist_all/0/0_10859.png\n",
      "../datasets/mnist_all/0/0_10861.png\n",
      "../datasets/mnist_all/0/0_10874.png\n",
      "../datasets/mnist_all/0/0_1090.png\n",
      "../datasets/mnist_all/0/0_10909.png\n",
      "../datasets/mnist_all/0/0_10914.png\n",
      "../datasets/mnist_all/0/0_10916.png\n",
      "../datasets/mnist_all/0/0_10919.png\n",
      "../datasets/mnist_all/0/0_10924.png\n",
      "../datasets/mnist_all/0/0_1093.png\n",
      "../datasets/mnist_all/0/0_10938.png\n",
      "../datasets/mnist_all/0/0_10974.png\n",
      "../datasets/mnist_all/0/0_10975.png\n",
      "../datasets/mnist_all/0/0_10992.png\n",
      "../datasets/mnist_all/0/0_11003.png\n",
      "../datasets/mnist_all/0/0_11014.png\n",
      "../datasets/mnist_all/0/0_11019.png\n",
      "../datasets/mnist_all/0/0_1102.png\n",
      "../datasets/mnist_all/0/0_11022.png\n",
      "../datasets/mnist_all/0/0_11026.png\n",
      "../datasets/mnist_all/0/0_11027.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvert_images_to_grayscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/grayscaled/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m root_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/grayscaled/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/sadeg/source/repos/ML-Algorithms-From-Scratch/K-Nearest-Neighbors/src/data_prepocessing.py:78\u001b[0m, in \u001b[0;36mconvert_images_to_grayscale\u001b[0;34m(source_root_directory, destination_root_directory, class_names)\u001b[0m\n\u001b[1;32m     76\u001b[0m image_destination_path \u001b[38;5;241m=\u001b[39m destination_root_directory\u001b[38;5;241m+\u001b[39mclass_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mimage_name\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_source_path)\n\u001b[0;32m---> 78\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_source_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#converitg to grayscale\u001b[39;00m\n\u001b[1;32m     80\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_images_to_grayscale(root_directory, '../datasets/grayscaled/', class_names)\n",
    "root_directory = '../datasets/grayscaled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the number of train, validation and test for each class \n",
    "total_sizes_each_class = [6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]\n",
    "val_percetage = 0\n",
    "test_percetage = .15\n",
    "train_size, val_size, test_size = calculate_train_val_test_sizes(total_sizes_each_class, val_percetage, test_percetage)\n",
    "\n",
    "#testing the size claculations\n",
    "total_recalculated = [x+y+z for x, y, z in zip(train_size, val_size, test_size)]\n",
    "total_recalculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spilitng the dataset into train, validation and test\n",
    "source_directory = '../datasets/grayscaled/'\n",
    "destination_directory ='../datasets/ready/'\n",
    "split_images_into_train_validation_test(source_directory, destination_directory, class_names, val_size, test_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
